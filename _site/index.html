<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Explanation Ontology: A General-Purpose, Semantic Representation for Supporting User-Centered Explanations &middot; Explanation Ontology - Modeling Explainability in User-Centered AI System Design
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon" sizes="144x144" href="/public/apple-touch-icon.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico?">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-146052-15', 'getpoole.com');
    ga('send', 'pageview');
  </script>
</head>


  <body class="theme-base-0e">

    <div class="sidebar">
  <div class="container sidebar-sticky">
<!--     <div class="sidebar-about">
      <h1>
        <a href="/">
          Explanation Ontology - Modeling Explainability in User-Centered AI System Design
        </a>
      </h1>
      <p class="lead"></p>
    </div> -->

    <nav class="sidebar-nav">
      <ul style="list-style: none;">
        <li><button class="collapsible">
<a class="sidebar-nav-item" href="/index">About</a></button>
        <div class="button-content">
        <ul>
          <li><a class="sidebar-nav-item" href="/index#abstract">Descriptions</a></li>

          <li><a class="sidebar-nav-item" href="/index#publications">Publications</a></li>

        </ul>
        </div>
        </li>      
      <li><button class="collapsible">
<a class="sidebar-nav-item" href="/ontology">Ontology</a></button>
        <div class="button-content">
        <ul>
          <li><a class="sidebar-nav-item" href="/ontology#ontologyabout">About Ontology</a></li>
          <li><a class="sidebar-nav-item" href="/ontology#ontologylinks">Access Links</a></li>
           <li><a class="sidebar-nav-item" href="/ontology#ontologymetadata">Ontology Metadata</a></li>

        </ul>
        </div>
        </li>
        <li><button class="collapsible">
<a class="sidebar-nav-item" href="/modeling">Explanation Types</a></button>
        <div class="button-content">
          <ul>
            <li><a class="sidebar-nav-item" href="/modeling#explanationtypes">Catalog</a></li>
            <li><a class="sidebar-nav-item" href="/modeling#modelingexplanations">Modeling</a></li>
          </ul>
        </div>
        </li>
         <li><a class="sidebar-nav-item" href="/clinicalexample">Use Cases</a></li>

        <li><button class="collapsible">
<a class="sidebar-nav-item" href="/competencyquestions">Competency Questions</a></button>
        <div class="button-content">
          <ul>
            <li><a class="sidebar-nav-item" href="/competencyquestions#sparql">SPARQL Queries</a></li>
          </ul>
        </div>
        </li>
        <li><button class="collapsible">
<a class="sidebar-nav-item" href="/index#resoruces">Resources</a></button>
        <div class="button-content">
        <ul>
          <li><a class="sidebar-nav-item" href="/protocol">Protocol Guidance</a></li>
          <li><a class="sidebar-nav-item" href="/presentations">Presentations</a></li>
          <li><a class="sidebar-nav-item" href="/index#toolsused">Tools Used</a></li>
        </ul>
        </div>
        </li>        
           
      

      

<!--       
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
       -->

      <!--<a class="sidebar-nav-item" href="https://g-nitin.github.io/ontology-website//archive/v2.1.0.zip">Download</a>-->
        <li><a class="sidebar-nav-item" href="https://g-nitin.github.io/ontology-website/">GitHub project</a></li>
      </ul>
      <!--<span class="sidebar-nav-item">Currently v2.1.0</span>-->
    </nav>

    <p>&copy; 2024. All rights reserved.</p>
  </div>
</div>


    <div class="content container" style="max-width: fit-content;">
      <table>
  <tbody>
    <tr>
      <td><a href="#abstract">Abstract</a></td>
      <td><a href="#resources">Resources</a></td>
      <td><a href="#toolsused">Tools Used</a></td>
      <td><a href="#contributors">Team</a></td>
      <td><a href="#publications">Publications</a></td>
    </tr>
  </tbody>
</table>

<h1 class="page-title" style="text-transform:uppercase;" id="header">Explanation Ontology: A General-Purpose, Semantic Representation for Supporting User-Centered Explanations</h1>

<p class="message">A website to navigate resources open-sourced for the Explanation Ontology. Use the side navigation panel to explore different sections of the website and click on an add symbol for more navigation options under some sections.</p>

<!-- <table>
  <tbody>
    <tr>
      <td><a href="#abstract">Abstract</a></td>
    </tr>
  </tbody>
</table> -->

<hr />

<article class="mb-5" id="abstract">
<content>
  
  
<h2>Abstract</h2>
  <p>In the past decade, trustworthy Artificial Intelligence (AI) has emerged as a focus for the AI community to ensure better adoption of AI models, and explainable AI is a cornerstone in this area. Over the years, the focus has shifted from building transparent AI methods to making recommendations on how to make black-box or opaque machine learning models and their results more understandable by experts and non-expert users. 
    <br />
    In our <a href="https://arxiv.org/abs/2010.01479">previous work</a>, to address the goal of supporting user-centered explanations that make model recommendations more explainable, we developed an Explanation Ontology (EO), a general-purpose representation, to help system designers, our intended users of the EO, connect explanations to their underlying data and knowledge. 
  <br />
    We now addresses the apparent need for improved interoperability to support a wider range of use cases. We expand the EO, mainly in the system attributes contributing to explanations, by introducing new classes and properties to support a broader range of state-of-the-art explainer models. We present the expanded ontology model, highlighting the classes and properties that are important to model a larger set of <em>fifteen</em> literature-backed explanation types that are supported within the EO.
  <br />
    We build on these explanation type descriptions to show how to utilize the EO model to represent explanations in <em>five</em> use cases spanning the domains of finance, food, and healthcare. We include competency questions that evaluate the EO's capabilities to provide guidance for system designers on how to apply our ontology to their own use cases. This guidance includes allowing system designers to query the EO directly and providing them exemplar queries to explore content in the EO represented use cases. 
  <br />
    We have released this significantly expanded version of the Explanation Ontology at <a href="https://purl.org/heals/eo">https://purl.org/heals/eo</a> and updated here on our <a href="https://tetherless-world.github.io/explanation-ontology">resource website</a>, with supporting documentation. 
  <br />
    Overall, through the EO model, we aim to help system designers be better informed about explanations and support these explanations that can be composed, given their systems' outputs from various AI models, including a mix of machine learning, logical and explainer models, and different types of data and knowledge available to their systems.</p>
 </content>
 
 <hr />
 <article class="mb-5" id="resources">
<content>
<h2>List of ResourcesÂ </h2>
<ul>
 <table style="width:100%">
    <tr>
    <th>Resources</th>
    <th>Links</th> 
  </tr>  
  <tr>
    <td>Ontology</td>
    <td><a href="ontology">Explanation Ontology</a> </td> 
  </tr>
  <tr>
    <td>Explanation Types</td>
    <td><a href="modeling#explanationtypes">Modeling</a> </td> 
  </tr>
    <!--<tr>
    <td> </td>
    <td> (b) <a href="./application.html">Faceted Browser</a> </td> 
  </tr>-->
    <tr>
    <td>Examples</td>
    <td><a href="clinicalexample">Use Case Examples</a> </td> 
  </tr>
   <tr>
    <td>Competency Questions </td>
    <td><a href="competencyquestions#sparql">SPARQL Queries</a> </td> 
  </tr>
   <tr>
      <tr>
    <td>Protocol Guidance on Usage of Ontology</td>
    <td><a href="protocol">Protocol</a> </td> 
  </tr>
    <td>Tools Used </td>
    <td><a href="index#toolsused">References to tools used</a> </td> 
  </tr>
</table>
  
 </ul>
 </content>
 
 <hr />
 
 <article class="mb-5" id="toolsused">
<content>
  
  
<h2>Tools Used during Development</h2>
  <ul>
  <li>Ontology Editor: <a href="https://protege.stanford.edu/products.php#desktop-protege">Protege 5.5.0</a></li>
  <li>Conceptual Diagram created using <a href="https://www.omnigroup.com/omnigraffle/">Omnigraffle</a></li>
  <li>Ontology documentation tool, <a href="https://github.com/dgarijo/Widoco">Widoco</a></li>
  <li>RDF Visualization generated with <a href="http://jimmccusker.github.io/rdfviewer/">RDFViewer</a> and <a href="https://github.com/protegeproject/ontograf">Ontograf</a> in Protege</li>
  </ul>
  </content>
  <!--<iframe src="https://tetherless-world.github.io/explanation-ontology/WidocoDocumentation/index-en.html" style="width:100%;"/>-->
  
    <hr />
   
    <article class="mb-5" id="contributors">
<content>
  <h2>Team</h2>
  <h3>Current Contributors</h3>
   Shruthi Chari<sup>1</sup>, Oshani Seneviratne<sup>1</sup>, Mohamed Ghalwash<sup>2</sup>, Sola Shirai<sup>1</sup> Daniel M. Gruen<sup>1</sup>, Pablo Meyer<sup>2</sup>, Prithwish Chakraborty<sup>2</sup>, Deborah L. McGuinness<sup>1</sup>
  <h3>Past Contributors</h3>
  Morgan Foreman<sup>2</sup>,  Amar K. Das<sup>2</sup>
<h3><a href="https://www.rpi.edu/"><sup>1</sup>Rensselaer Polytechnic Institute</a> | <a href="https://research.ibm.com/science"><sup>2</sup>IBM Research</a></h3>
   </content>
 
  <article class="mb-5" id="publications">
<content>
  <h2>Publications</h2>
  <ul>
    <li>Chari, Shruthi, Oshani Seneviratne, Mohamed Ghalwash, Sola Shirai, Daniel M. Gruen, Pablo Meyer, Prithwish Chakraborty, and Deborah L. McGuinness. "Explanation Ontology: A General-Purpose, Semantic Representation for Supporting User-Centered Explanations."</li>
    <li>Chari, Shruthi, Prasant Acharya, Daniel M. Gruen, Olivia Zhang, Elif K. Eyigoz, Mohamed Ghalwash, Oshani Seneviratne et al. "Informing clinical assessment by contextualizing post-hoc explanations of risk prediction models in type-2 diabetes." Artificial Intelligence in Medicine 137 (2023): 102498</li>
    <li>Chari, Shruthi, Prithwish Chakraborty, Mohamed Ghalwash, Oshani Seneviratne, Elif K. Eyigoz, Daniel M. Gruen, Fernando Suarez Saiz, Ching-Hua Chen, Pablo Meyer Rojas, and Deborah L. McGuinness. "Leveraging Clinical Context for User-Centered Explainability: A Diabetes Use Case." arXiv preprint arXiv:2107.02359 (2021).</li>
    <li>Padhiar, I., Seneviratne, O., Chari, S., Gruen, D., &amp; McGuinness, D. L. (2021, April). Semantic modeling for food recommendation explanations. In 2021 IEEE 37th International Conference on Data Engineering Workshops (ICDEW) (pp. 13-19). IEEE.</li>
    <li>[<b>Best Paper</b>] Chari, S., Chakraborty, P., Seneviratne, O., Ghalwash, M., Gruen, D. M., Sow, D., &amp; McGuinness, D. L. (2021). Towards Clinically Relevant Explanations for Type-2 Diabetes Risk Prediction with the Explanation Ontology. AMIA.</li>
    <li>Gruen, Daniel M., Shruthi Chari, Morgan A. Foreman, Oshani Seneviratne, Rachel Richesson, Amar K. Das, and Deborah L. McGuinness. "Designing for ai explainability in clinical context." AAAI, 2021.</li>
    <li>[<b>Best Resource Paper</b>] Explanation Ontology: A Model of Explanations for User-Centered AI; Shruthi Chari , Oshani Seneviratne , Daniel M. Gruen ,  Morgan A. Foreman , Amar K. Das, Deborah L. McGuinness; Resource Track,19th International Semantic Web Conference 2020</li>
    <li>Explanation Ontology in Action: A Clinical Use-Case; Shruthi Chari , Oshani Seneviratne , Daniel M. Gruen ,  Morgan A. Foreman , Amar K. Das, Deborah L. McGuinness; Posters and Demo Track,19th International Semantic Web Conference 2020</li>
    <li>S Chari, O Seneviratne, DM Gruen, DL McGuinness. "Foundations of Explainable Knowledge-Enabled Systems." In Ilaria Tiddi, Freddy Lecue, Pascal Hitzler (eds.), Knowledge Graphs for eXplainable AI -- Foundations, Applications and Challenges. Studies on the Semantic Web, pp 23 - 48; 2020</li>
<li>S Chari, O Seneviratne, DM Gruen, DL McGuinness. "Directions for Explainable Knowledge-Enabled Systems." In Ilaria Tiddi, Freddy Lecue, Pascal Hitzler (eds.), Knowledge Graphs for eXplainable AI -- Foundations, Applications and Challenges. Studies on the Semantic Web, pp 245 - 261; 2020</li>
  </ul>
  </content>
<!-- 
<div class="posts">
  
</div>

<div class="pagination">
  
    <span class="pagination-item older">Older</span>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div> -->
</article></article></article></article></article>

    </div>
  <script>
    var coll = document.getElementsByClassName("collapsible");
    var i;

    for (i = 0; i < coll.length; i++) {
      coll[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.maxHeight){
          content.style.maxHeight = null;
        } else {
          content.style.maxHeight = content.scrollHeight + "px";
        } 
      });
    }
</script>
  </body>
</html>
