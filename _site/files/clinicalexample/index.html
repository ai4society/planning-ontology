<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Use Cases &middot; Explanation Ontology - Modeling Explainability in User-Centered AI System Design
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon" sizes="144x144" href="/public/apple-touch-icon.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico?">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-146052-15', 'getpoole.com');
    ga('send', 'pageview');
  </script>
</head>


  <body class="theme-base-0e">

    <div class="sidebar">
  <div class="container sidebar-sticky">
<!--     <div class="sidebar-about">
      <h1>
        <a href="/">
          Explanation Ontology - Modeling Explainability in User-Centered AI System Design
        </a>
      </h1>
      <p class="lead"></p>
    </div> -->

    <nav class="sidebar-nav">
      <ul style="list-style: none;">
        <li><button class="collapsible">
<a class="sidebar-nav-item" href="/files/index">About</a></button>
        <div class="button-content">
        <ul>
          <li><a class="sidebar-nav-item" href="/files/index#abstract">Descriptions</a></li>

          <li><a class="sidebar-nav-item" href="/files/index#publications">Publications</a></li>

        </ul>
        </div>
        </li>      
      <li><button class="collapsible">
<a class="sidebar-nav-item" href="/files/ontology">Ontology</a></button>
        <div class="button-content">
        <ul>
          <li><a class="sidebar-nav-item" href="/files/ontology#ontologyabout">About Ontology</a></li>
          <li><a class="sidebar-nav-item" href="/files/ontology#ontologylinks">Access Links</a></li>
           <li><a class="sidebar-nav-item" href="/files/ontology#ontologymetadata">Ontology Metadata</a></li>

        </ul>
        </div>
        </li>
        <li><button class="collapsible">
<a class="sidebar-nav-item" href="/files/modeling">Explanation Types</a></button>
        <div class="button-content">
          <ul>
            <li><a class="sidebar-nav-item" href="/files/modeling#explanationtypes">Catalog</a></li>
            <li><a class="sidebar-nav-item" href="/files/modeling#modelingexplanations">Modeling</a></li>
          </ul>
        </div>
        </li>
         <li><a class="sidebar-nav-item" href="/files/clinicalexample">Use Cases</a></li>

        <li><button class="collapsible">
<a class="sidebar-nav-item" href="/files/competencyquestions">Competency Questions</a></button>
        <div class="button-content">
          <ul>
            <li><a class="sidebar-nav-item" href="/files/competencyquestions#sparql">SPARQL Queries</a></li>
          </ul>
        </div>
        </li>
        <li><button class="collapsible">
<a class="sidebar-nav-item" href="/files/index#resoruces">Resources</a></button>
        <div class="button-content">
        <ul>
          <li><a class="sidebar-nav-item" href="/files/protocol">Protocol Guidance</a></li>
          <li><a class="sidebar-nav-item" href="/files/presentations">Presentations</a></li>
          <li><a class="sidebar-nav-item" href="/files/index#toolsused">Tools Used</a></li>
        </ul>
        </div>
        </li>        
           
      

      

<!--       
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
       -->

      <!--<a class="sidebar-nav-item" href="https://g-nitin.github.io/ontology-website//archive/v2.1.0.zip">Download</a>-->
        <li><a class="sidebar-nav-item" href="https://g-nitin.github.io/ontology-website/">GitHub project</a></li>
      </ul>
      <!--<span class="sidebar-nav-item">Currently v2.1.0</span>-->
    </nav>

    <p>&copy; 2024. All rights reserved.</p>
  </div>
</div>


    <div class="content container" style="max-width: fit-content;">
      <article class="mb-5" id="usecases">
<content>
  
  
<h3>Exemplar Use Cases</h3>
  <p>We showcase the utility and ability of the Explanation Ontology to represent use cases that span representative and high-precision domains of finance and healthcare. In each of these use cases, we show how the EO can represent explanations in instances where outputs of AI methods have been produced. We also show visually show against each use case, the explanation types inferred when the Protege reasoner is run on these use case knowledge graphs. Each of these use case files, both the <a href="/files/usecases">original</a> and <a href="/files/usecases/inferred">inferred</a> KGs, have been made available on our Github. </p>
  <table id="catalogusecases">
    <th>Use Case</th><th>Explanation Types Inferred</th><th>File</th>
    <tr><td><a href="#clinicalexample">Clinical</a></td><td>Contrastive</td><td><a href="/files/usecases/contrastiveexp.rdf">Clinical Example</a></td></tr>
    <tr><td><a href="#clinicalexample">Food Recommendation</a></td><td>Contrastive and Contextual</td><td><a href="/files/usecases/eo_foodrecommendationusecase.rdf">Food Rec. Example</a></td></tr>
     <tr><td><a href="#clinicalexample">Proactive Retention</a></td><td>Rationale</td><td><a href="/files/usecases/eo_proactiveretentionusecase.rdf">Proactive Retention Example</a></td></tr>
     <tr><td><a href="#clinicalexample">Health Survey Analysis</a></td><td>Case based and Contextual</td><td><a href="/files/usecases/eo_nhanesusecase.rdf">NHANES Example</a></td></tr>
     <tr><td><a href="#clinicalexample">Medical Expenditure</a></td><td>Data</td><td><a href="/files/usecases/eo_medicalexpenditureusecase.rdf">Medical Expenditure Example</a></td></tr>
     <tr><td><a href="#clinicalexample">Credit Approval</a></td><td>Data, Case based and Contrastive</td><td><a href="/files/usecases/eo_creditapprovalusecase.rdf">Credit Approval Example</a></td></tr>
    
    
    </table>
  
 </content>
 <hr />
<article class="mb-5" id="clinicalexample">
<content>
  
  
<h3>Example from Clinical Requirement Gatherings Session</h3>
  <p>We present an example of how our explanations ontology could be used to address a question, "Why Drug B over Drug A?" that clearly requires a contrastive explanation. Given that a contrastive explanation is the most suitable explanation type to address this question, our ontology if loaded into a system can help guide a system designer to locate the <strong>facts</strong> in support of Drug A and <strong>foil</strong> in support/against Drug B. While this is a real question that was asked by one of the clincians to a prototype decision support tool that we built to walk them through a complicated type-2 diabetes patient case, we omit the exact explanation as it is difficult to explain without the entire context of the patient case and the knowledge available to the system. Instead, we present an abstracted up example of a contrastive explanation in <a href="#fig2">Fig. 2</a>. </p>
  <!--In <a href="#fig3">Fig. 3</a>, we also show how our ontology would have inferred the explanation to be of a <strong>contrastive</strong> kind if the system had generated two recommendations one based on the facts supporting Drug A and one on the foil ruling out drug B.-->
  
 <img src="/files/images/usecases/clinicalexample.png" style="width:100%; height:100%" />  
  <caption id="fig2">Fig 2. A visual overview of the RDF representation of a contrastive explanation that addresses the question, "Why Drug B over A?"</caption>
  <br />
    <p>The RDF snippet can be browsed at and is available within our Github repository at : <a href="https://raw.githubusercontent.com/tetherless-world/explanation-ontology/master/annotations/contrastiveexp.rdf">https://raw.githubusercontent.com/tetherless-world/explanation-ontology/master/annotations/contrastiveexp.rdf</a></p>
  
  <br />
<!--<img src="/files/images/ProtegeSnapshot.png" style="width:100%; height:100%">  
  <caption id="fig3">Fig 3. A snapshot of classification results obtained by running <a href="https://github.com/stardog-union/pellet">Pellet reasoner</a> within <a href="https://protege.stanford.edu/">Protege</a> which depict how an explanation based on two system recommendations that were supported by a fact and foil respectively were inferred to be of a contrastive type. The reasoner leveraged the encoding of <a href="#explanationtypes">sufficiency conditions for each explanation type</a> that we support as OWL restrictions within our ontology.</caption>-->
  
 </content>
</article></article>

    </div>
  <script>
    var coll = document.getElementsByClassName("collapsible");
    var i;

    for (i = 0; i < coll.length; i++) {
      coll[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.maxHeight){
          content.style.maxHeight = null;
        } else {
          content.style.maxHeight = content.scrollHeight + "px";
        } 
      });
    }
</script>
  </body>
</html>
